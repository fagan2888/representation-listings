{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.pymc.io/notebooks/GLM-hierarchical.html or a random effects model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy.stats import ttest_ind, linregress\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import scale\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "%matplotlib inline\n",
    "tracts_data_path = 'data/features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = {'GEOID' : str,\n",
    "          'place_geoid' : str,\n",
    "          'state' : str,\n",
    "          'county' : str}\n",
    "\n",
    "df = pd.read_csv(tracts_data_path, encoding='utf-8', dtype=dtypes)\n",
    "df = df.rename(columns={'GEOID' : 'tract'}).set_index('tract')\n",
    "assert df.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12328\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>land_area</th>\n",
       "      <th>place_geoid</th>\n",
       "      <th>place_name</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>median_age</th>\n",
       "      <th>pct_hispanic</th>\n",
       "      <th>pct_white</th>\n",
       "      <th>pct_black</th>\n",
       "      <th>pct_asian</th>\n",
       "      <th>pct_single_fam_detached</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_burden</th>\n",
       "      <th>median_gross_rent_k</th>\n",
       "      <th>med_income_k</th>\n",
       "      <th>med_home_value_k</th>\n",
       "      <th>pct_white_change_2012_2015</th>\n",
       "      <th>clist_count</th>\n",
       "      <th>prop_count</th>\n",
       "      <th>bias_diff</th>\n",
       "      <th>bias_ratio</th>\n",
       "      <th>bias_log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tract</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01073000100</th>\n",
       "      <td>7549578</td>\n",
       "      <td>0107000</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>2970.0</td>\n",
       "      <td>32.2</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.754</td>\n",
       "      <td>24.359</td>\n",
       "      <td>68.4</td>\n",
       "      <td>0.014</td>\n",
       "      <td>3</td>\n",
       "      <td>2.150039</td>\n",
       "      <td>0.849961</td>\n",
       "      <td>1.269826</td>\n",
       "      <td>0.238880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01073000300</th>\n",
       "      <td>2093104</td>\n",
       "      <td>0107000</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>2494.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.552</td>\n",
       "      <td>20.425</td>\n",
       "      <td>65.3</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>1</td>\n",
       "      <td>2.852092</td>\n",
       "      <td>-1.852092</td>\n",
       "      <td>0.519198</td>\n",
       "      <td>-0.655469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01073000400</th>\n",
       "      <td>8001582</td>\n",
       "      <td>0107000</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>3437.0</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.912</td>\n",
       "      <td>21.759</td>\n",
       "      <td>60.7</td>\n",
       "      <td>0.025</td>\n",
       "      <td>2</td>\n",
       "      <td>2.120786</td>\n",
       "      <td>-0.120786</td>\n",
       "      <td>0.961296</td>\n",
       "      <td>-0.039473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01073000500</th>\n",
       "      <td>4819145</td>\n",
       "      <td>0107000</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>3735.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.534</td>\n",
       "      <td>21.430</td>\n",
       "      <td>53.7</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0</td>\n",
       "      <td>3.426167</td>\n",
       "      <td>-3.426167</td>\n",
       "      <td>0.225929</td>\n",
       "      <td>-1.487534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01073000700</th>\n",
       "      <td>3520564</td>\n",
       "      <td>0107000</td>\n",
       "      <td>Birmingham, AL</td>\n",
       "      <td>2562.0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.505</td>\n",
       "      <td>15.833</td>\n",
       "      <td>52.4</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>2.135412</td>\n",
       "      <td>-2.135412</td>\n",
       "      <td>0.318937</td>\n",
       "      <td>-1.142761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             land_area place_geoid      place_name  total_pop  median_age  \\\n",
       "tract                                                                       \n",
       "01073000100    7549578     0107000  Birmingham, AL     2970.0        32.2   \n",
       "01073000300    2093104     0107000  Birmingham, AL     2494.0        36.5   \n",
       "01073000400    8001582     0107000  Birmingham, AL     3437.0        30.6   \n",
       "01073000500    4819145     0107000  Birmingham, AL     3735.0        35.8   \n",
       "01073000700    3520564     0107000  Birmingham, AL     2562.0        25.4   \n",
       "\n",
       "             pct_hispanic  pct_white  pct_black  pct_asian  \\\n",
       "tract                                                        \n",
       "01073000100         0.046      0.171      0.785      0.000   \n",
       "01073000300         0.180      0.046      0.672      0.084   \n",
       "01073000400         0.007      0.079      0.908      0.000   \n",
       "01073000500         0.014      0.050      0.929      0.000   \n",
       "01073000700         0.025      0.000      0.977      0.000   \n",
       "\n",
       "             pct_single_fam_detached    ...     pct_burden  \\\n",
       "tract                                   ...                  \n",
       "01073000100                    0.705    ...          0.604   \n",
       "01073000300                    0.326    ...          0.534   \n",
       "01073000400                    0.897    ...          0.747   \n",
       "01073000500                    0.546    ...          0.547   \n",
       "01073000700                    0.569    ...          0.773   \n",
       "\n",
       "             median_gross_rent_k  med_income_k  med_home_value_k  \\\n",
       "tract                                                              \n",
       "01073000100                0.754        24.359              68.4   \n",
       "01073000300                0.552        20.425              65.3   \n",
       "01073000400                0.912        21.759              60.7   \n",
       "01073000500                0.534        21.430              53.7   \n",
       "01073000700                0.505        15.833              52.4   \n",
       "\n",
       "             pct_white_change_2012_2015  clist_count  prop_count  bias_diff  \\\n",
       "tract                                                                         \n",
       "01073000100                       0.014            3    2.150039   0.849961   \n",
       "01073000300                      -0.022            1    2.852092  -1.852092   \n",
       "01073000400                       0.025            2    2.120786  -0.120786   \n",
       "01073000500                       0.011            0    3.426167  -3.426167   \n",
       "01073000700                      -0.001            0    2.135412  -2.135412   \n",
       "\n",
       "             bias_ratio  bias_log  \n",
       "tract                              \n",
       "01073000100    1.269826  0.238880  \n",
       "01073000300    0.519198 -0.655469  \n",
       "01073000400    0.961296 -0.039473  \n",
       "01073000500    0.225929 -1.487534  \n",
       "01073000700    0.318937 -1.142761  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4858\n",
      "2763\n",
      "229\n",
      "2256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12328"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dummies representing if each race is majority in tract\n",
    "df['dummy_white'] = df['pct_white'].map(lambda x: 1 if x > 0.5 else 0)\n",
    "df['dummy_asian'] = df['pct_asian'].map(lambda x: 1 if x > 0.5 else 0)\n",
    "df['dummy_black'] = df['pct_black'].map(lambda x: 1 if x > 0.5 else 0)\n",
    "df['dummy_hispanic'] = df['pct_hispanic'].map(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "print(df['dummy_white'].sum())\n",
    "print(df['dummy_black'].sum())\n",
    "print(df['dummy_asian'].sum())\n",
    "print(df['dummy_hispanic'].sum())\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# or, dummies representing if each race is plurality in tract\\nmask = (df['pct_white'] > df['pct_hispanic']) & (df['pct_white'] > df['pct_asian']) & (df['pct_white'] > df['pct_black'])\\ndf['dummy_white'] = mask.astype(int)\\n\\nmask = (df['pct_hispanic'] > df['pct_white']) & (df['pct_hispanic'] > df['pct_asian']) & (df['pct_hispanic'] > df['pct_black'])\\ndf['dummy_hispanic'] = mask.astype(int)\\n\\nmask = (df['pct_black'] > df['pct_white']) & (df['pct_black'] > df['pct_asian']) & (df['pct_black'] > df['pct_hispanic'])\\ndf['dummy_black'] = mask.astype(int)\\n\\nmask = (df['pct_asian'] > df['pct_white']) & (df['pct_asian'] > df['pct_black']) & (df['pct_asian'] > df['pct_hispanic'])\\ndf['dummy_asian'] = mask.astype(int)\\n\\nprint(df['dummy_white'].sum())\\nprint(df['dummy_black'].sum())\\nprint(df['dummy_asian'].sum())\\nprint(df['dummy_hispanic'].sum())\\nlen(df)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# or, dummies representing if each race is plurality in tract\n",
    "mask = (df['pct_white'] > df['pct_hispanic']) & (df['pct_white'] > df['pct_asian']) & (df['pct_white'] > df['pct_black'])\n",
    "df['dummy_white'] = mask.astype(int)\n",
    "\n",
    "mask = (df['pct_hispanic'] > df['pct_white']) & (df['pct_hispanic'] > df['pct_asian']) & (df['pct_hispanic'] > df['pct_black'])\n",
    "df['dummy_hispanic'] = mask.astype(int)\n",
    "\n",
    "mask = (df['pct_black'] > df['pct_white']) & (df['pct_black'] > df['pct_asian']) & (df['pct_black'] > df['pct_hispanic'])\n",
    "df['dummy_black'] = mask.astype(int)\n",
    "\n",
    "mask = (df['pct_asian'] > df['pct_white']) & (df['pct_asian'] > df['pct_black']) & (df['pct_asian'] > df['pct_hispanic'])\n",
    "df['dummy_asian'] = mask.astype(int)\n",
    "\n",
    "print(df['dummy_white'].sum())\n",
    "print(df['dummy_black'].sum())\n",
    "print(df['dummy_asian'].sum())\n",
    "print(df['dummy_hispanic'].sum())\n",
    "len(df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## determine if tracts are over or under represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "overrepresent_var = 'bias_ratio'\n",
    "overrepresent_value = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3078 9250\n"
     ]
    }
   ],
   "source": [
    "# divide data into two subsets: overrepresented vs proportionately&under-represented\n",
    "mask = df[overrepresent_var] > overrepresent_value\n",
    "over = df[mask]\n",
    "under = df[~mask]\n",
    "print(len(over), len(under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9250\n",
       "1    3078\n",
       "Name: is_over, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a dummy to indicate if tract is overrepresented\n",
    "df['is_over'] = df[overrepresent_var].map(lambda x: 1 if x > overrepresent_value else 0)\n",
    "df['is_over'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a set of all predictor variables\n",
    "cols = ['bias_diff', 'bias_ratio', 'bias_log', 'centroid', 'clist_count', 'county', \n",
    "        'geometry', 'is_over', 'land_area', 'lat_city_center', 'lng_city_center',\n",
    "        'place_geoid', 'place_name', 'prop_count', 'state', 'pct_white_change_2012_2015']\n",
    "predictors_all = df.drop(columns=cols).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3662000823384109 0.2183406113537118 0.167933405718422 0.11125886524822695\n",
      "1.6771963771099219\n",
      "2.1806267834073907\n",
      "3.2914238476312945\n"
     ]
    }
   ],
   "source": [
    "# what proportion of tracts with each of these races as the majority is over-represented?\n",
    "white_tracts = df[df['dummy_white']==1]\n",
    "white_odds = white_tracts['is_over'].sum() / len(white_tracts)\n",
    "\n",
    "asian_tracts = df[df['dummy_asian']==1]\n",
    "asian_odds = asian_tracts['is_over'].sum() / len(asian_tracts)\n",
    "\n",
    "black_tracts = df[df['dummy_black']==1]\n",
    "black_odds = black_tracts['is_over'].sum() / len(black_tracts)\n",
    "\n",
    "hisp_tracts = df[df['dummy_hispanic']==1]\n",
    "hisp_odds = hisp_tracts['is_over'].sum() / len(hisp_tracts)\n",
    "\n",
    "print(white_odds, asian_odds, black_odds, hisp_odds)\n",
    "print(white_odds / asian_odds)\n",
    "print(white_odds / black_odds)\n",
    "print(white_odds / hisp_odds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority white tracts are overrepresented on Craigslist 2x as often as majority black tracts and 3x  as often as majority hispanic tracts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gini coefficient measures how evenly some value is distributed among a set of buckets\n",
    "# we can measure how evenly listings are distributed among tracts\n",
    "def gini(list_of_values):\n",
    "    sorted_list = sorted(list_of_values)\n",
    "    height, area = 0, 0\n",
    "    for value in sorted_list:\n",
    "        height += value\n",
    "        area += height - value / 2.\n",
    "    fair_area = height * len(list_of_values) / 2.\n",
    "    return (fair_area - area) / fair_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7958107050169203\n",
      "0.539665690899946\n",
      "0.38384089826328704\n"
     ]
    }
   ],
   "source": [
    "# nationwide\n",
    "print(gini(df['clist_count']))\n",
    "print(gini(df['prop_count']))\n",
    "print(gini(df['count_renter_occupied_units']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ prop_count is a function of per-city count_renter_occupied_units, but their gini coefficients don't match nationwide because prop_count is assigned as per-city proportions, not nationwide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clist_gini</th>\n",
       "      <th>prop_gini</th>\n",
       "      <th>ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hartford, CT</th>\n",
       "      <td>0.826</td>\n",
       "      <td>0.262</td>\n",
       "      <td>3.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miami, FL</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.284</td>\n",
       "      <td>2.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philadelphia, PA</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.274</td>\n",
       "      <td>2.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston, MA</th>\n",
       "      <td>0.721</td>\n",
       "      <td>0.266</td>\n",
       "      <td>2.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milwaukee, WI</th>\n",
       "      <td>0.769</td>\n",
       "      <td>0.290</td>\n",
       "      <td>2.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buffalo, NY</th>\n",
       "      <td>0.616</td>\n",
       "      <td>0.236</td>\n",
       "      <td>2.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Providence, RI</th>\n",
       "      <td>0.591</td>\n",
       "      <td>0.229</td>\n",
       "      <td>2.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detroit, MI</th>\n",
       "      <td>0.781</td>\n",
       "      <td>0.310</td>\n",
       "      <td>2.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sacramento, CA</th>\n",
       "      <td>0.679</td>\n",
       "      <td>0.270</td>\n",
       "      <td>2.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cleveland, OH</th>\n",
       "      <td>0.727</td>\n",
       "      <td>0.290</td>\n",
       "      <td>2.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St. Louis, MO</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.297</td>\n",
       "      <td>2.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baltimore, MD</th>\n",
       "      <td>0.773</td>\n",
       "      <td>0.318</td>\n",
       "      <td>2.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago, IL</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.372</td>\n",
       "      <td>2.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles, CA</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.332</td>\n",
       "      <td>2.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Birmingham, AL</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.328</td>\n",
       "      <td>2.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salt Lake City, UT</th>\n",
       "      <td>0.736</td>\n",
       "      <td>0.315</td>\n",
       "      <td>2.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisville, KY</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.297</td>\n",
       "      <td>2.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Orleans, LA</th>\n",
       "      <td>0.682</td>\n",
       "      <td>0.316</td>\n",
       "      <td>2.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Charlotte, NC</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.351</td>\n",
       "      <td>2.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington, DC</th>\n",
       "      <td>0.693</td>\n",
       "      <td>0.331</td>\n",
       "      <td>2.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tampa, FL</th>\n",
       "      <td>0.650</td>\n",
       "      <td>0.313</td>\n",
       "      <td>2.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco, CA</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.332</td>\n",
       "      <td>2.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Memphis, TN</th>\n",
       "      <td>0.652</td>\n",
       "      <td>0.317</td>\n",
       "      <td>2.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston, TX</th>\n",
       "      <td>0.808</td>\n",
       "      <td>0.393</td>\n",
       "      <td>2.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indianapolis, IN</th>\n",
       "      <td>0.727</td>\n",
       "      <td>0.357</td>\n",
       "      <td>2.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riverside, CA</th>\n",
       "      <td>0.706</td>\n",
       "      <td>0.350</td>\n",
       "      <td>2.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York, NY</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.430</td>\n",
       "      <td>1.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pittsburgh, PA</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.352</td>\n",
       "      <td>1.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Antonio, TX</th>\n",
       "      <td>0.743</td>\n",
       "      <td>0.379</td>\n",
       "      <td>1.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Atlanta, GA</th>\n",
       "      <td>0.686</td>\n",
       "      <td>0.351</td>\n",
       "      <td>1.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Columbus, OH</th>\n",
       "      <td>0.680</td>\n",
       "      <td>0.350</td>\n",
       "      <td>1.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portland, OR</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.364</td>\n",
       "      <td>1.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dallas, TX</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.411</td>\n",
       "      <td>1.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Richmond, VA</th>\n",
       "      <td>0.719</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Jose, CA</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.393</td>\n",
       "      <td>1.911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cincinnati, OH</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.309</td>\n",
       "      <td>1.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jacksonville, FL</th>\n",
       "      <td>0.651</td>\n",
       "      <td>0.347</td>\n",
       "      <td>1.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denver, CO</th>\n",
       "      <td>0.676</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nashville, TN</th>\n",
       "      <td>0.675</td>\n",
       "      <td>0.361</td>\n",
       "      <td>1.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seattle, WA</th>\n",
       "      <td>0.692</td>\n",
       "      <td>0.371</td>\n",
       "      <td>1.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phoenix, AZ</th>\n",
       "      <td>0.651</td>\n",
       "      <td>0.352</td>\n",
       "      <td>1.851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Diego, CA</th>\n",
       "      <td>0.696</td>\n",
       "      <td>0.377</td>\n",
       "      <td>1.848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orlando, FL</th>\n",
       "      <td>0.651</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Raleigh, NC</th>\n",
       "      <td>0.666</td>\n",
       "      <td>0.372</td>\n",
       "      <td>1.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Las Vegas, NV</th>\n",
       "      <td>0.541</td>\n",
       "      <td>0.323</td>\n",
       "      <td>1.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minneapolis, MN</th>\n",
       "      <td>0.678</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austin, TX</th>\n",
       "      <td>0.601</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia Beach, VA</th>\n",
       "      <td>0.690</td>\n",
       "      <td>0.442</td>\n",
       "      <td>1.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas City, MO</th>\n",
       "      <td>0.548</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma City, OK</th>\n",
       "      <td>0.656</td>\n",
       "      <td>0.429</td>\n",
       "      <td>1.530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    clist_gini  prop_gini  ratio\n",
       "Hartford, CT             0.826      0.262  3.155\n",
       "Miami, FL                0.789      0.284  2.783\n",
       "Philadelphia, PA         0.756      0.274  2.761\n",
       "Boston, MA               0.721      0.266  2.709\n",
       "Milwaukee, WI            0.769      0.290  2.654\n",
       "Buffalo, NY              0.616      0.236  2.608\n",
       "Providence, RI           0.591      0.229  2.579\n",
       "Detroit, MI              0.781      0.310  2.516\n",
       "Sacramento, CA           0.679      0.270  2.511\n",
       "Cleveland, OH            0.727      0.290  2.509\n",
       "St. Louis, MO            0.742      0.297  2.496\n",
       "Baltimore, MD            0.773      0.318  2.430\n",
       "Chicago, IL              0.890      0.372  2.391\n",
       "Los Angeles, CA          0.788      0.332  2.369\n",
       "Birmingham, AL           0.767      0.328  2.338\n",
       "Salt Lake City, UT       0.736      0.315  2.338\n",
       "Louisville, KY           0.676      0.297  2.274\n",
       "New Orleans, LA          0.682      0.316  2.158\n",
       "Charlotte, NC            0.737      0.351  2.102\n",
       "Washington, DC           0.693      0.331  2.093\n",
       "Tampa, FL                0.650      0.313  2.080\n",
       "San Francisco, CA        0.690      0.332  2.080\n",
       "Memphis, TN              0.652      0.317  2.058\n",
       "Houston, TX              0.808      0.393  2.053\n",
       "Indianapolis, IN         0.727      0.357  2.036\n",
       "Riverside, CA            0.706      0.350  2.016\n",
       "New York, NY             0.855      0.430  1.988\n",
       "Pittsburgh, PA           0.694      0.352  1.968\n",
       "San Antonio, TX          0.743      0.379  1.962\n",
       "Atlanta, GA              0.686      0.351  1.957\n",
       "Columbus, OH             0.680      0.350  1.941\n",
       "Portland, OR             0.699      0.364  1.923\n",
       "Dallas, TX               0.787      0.411  1.916\n",
       "Richmond, VA             0.719      0.376  1.914\n",
       "San Jose, CA             0.751      0.393  1.911\n",
       "Cincinnati, OH           0.580      0.309  1.878\n",
       "Jacksonville, FL         0.651      0.347  1.878\n",
       "Denver, CO               0.676      0.362  1.867\n",
       "Nashville, TN            0.675      0.361  1.867\n",
       "Seattle, WA              0.692      0.371  1.867\n",
       "Phoenix, AZ              0.651      0.352  1.851\n",
       "San Diego, CA            0.696      0.377  1.848\n",
       "Orlando, FL              0.651      0.362  1.799\n",
       "Raleigh, NC              0.666      0.372  1.791\n",
       "Las Vegas, NV            0.541      0.323  1.676\n",
       "Minneapolis, MN          0.678      0.408  1.660\n",
       "Austin, TX               0.601      0.366  1.642\n",
       "Virginia Beach, VA       0.690      0.442  1.563\n",
       "Kansas City, MO          0.548      0.353  1.553\n",
       "Oklahoma City, OK        0.656      0.429  1.530"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now examine gini coefficients for each city\n",
    "data = {}\n",
    "for name, group in df.groupby('place_name'):\n",
    "    \n",
    "    data[name] = {'clist_gini' : gini(group['clist_count']),\n",
    "                  'prop_gini' : gini(group['prop_count'])}\n",
    "    \n",
    "ginis = pd.DataFrame(data).T\n",
    "ginis['ratio'] = ginis['clist_gini'] / ginis['prop_gini']\n",
    "ginis.sort_values(by = 'ratio', ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher gini coefficient for actual craigslist listings suggests they are more concentrated into fewer tracts than a proportional distribution would be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *t*-tests and effect sizes for significant differences in variables\n",
    "\n",
    "Divide the data into two subsets: overrepresented and underrepresented, then test if variables' means differ significantly between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# effect size: as cohen's d\n",
    "def cohen_d(x, y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    d = (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)\n",
    "    return d\n",
    "\n",
    "def test_variables(subset1, subset2, variables):\n",
    "    test_results = {}\n",
    "    for var in variables:\n",
    "        a = subset1[var]\n",
    "        b = subset2[var]\n",
    "        t_statistic, p_value = ttest_ind(a=a, b=b, equal_var=False, nan_policy='omit')\n",
    "        diff = subset1[var].mean() - subset2[var].mean()\n",
    "        d_value = cohen_d(x=a, y=b)\n",
    "        test_results[var] = {'diff_mean' : round(diff, 3),\n",
    "                             't_stat' : round(t_statistic, 2),\n",
    "                             'p_val' : round(p_value, 3),\n",
    "                             'cohen_d' : round(d_value, 2)}\n",
    "    return test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohen_d</th>\n",
       "      <th>diff_mean</th>\n",
       "      <th>p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pct_bachelors_or_higher</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_income_k</th>\n",
       "      <td>0.59</td>\n",
       "      <td>17.104</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_white</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_college_grad_student</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_gross_rent_k</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_20_34</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_english_only</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_nonrelatives_household</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_home_value_k</th>\n",
       "      <td>0.33</td>\n",
       "      <td>74.523</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_renter_occupied_units</th>\n",
       "      <td>0.13</td>\n",
       "      <td>80.796</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_age</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_asian</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rental_vacancy_rate</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renter_occupied_units_km</th>\n",
       "      <td>0.05</td>\n",
       "      <td>144.659</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_pop</th>\n",
       "      <td>0.05</td>\n",
       "      <td>93.288</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_commute_drive_alone</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_rooms_in_house</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_single_fam_detached</th>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_density_k_km</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.672</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_built_before_1940</th>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_to_center_km</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.601</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_renting</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_black</th>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_foreign_born</th>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_below_poverty</th>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_burden</th>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_hispanic</th>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_same_residence_year_ago</th>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_travel_time_work</th>\n",
       "      <td>-0.42</td>\n",
       "      <td>-3.351</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renter_household_size</th>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.330</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             cohen_d  diff_mean  p_val\n",
       "pct_bachelors_or_higher         0.80      0.171  0.000\n",
       "med_income_k                    0.59     17.104  0.000\n",
       "pct_white                       0.58      0.170  0.000\n",
       "pct_college_grad_student        0.53      0.098  0.000\n",
       "median_gross_rent_k             0.49      0.179  0.000\n",
       "pct_20_34                       0.39      0.039  0.000\n",
       "pct_english_only                0.37      0.093  0.000\n",
       "pct_nonrelatives_household      0.36      0.022  0.000\n",
       "med_home_value_k                0.33     74.523  0.000\n",
       "count_renter_occupied_units     0.13     80.796  0.000\n",
       "median_age                      0.11      0.703  0.000\n",
       "pct_asian                       0.08      0.009  0.000\n",
       "rental_vacancy_rate             0.07      0.468  0.001\n",
       "renter_occupied_units_km        0.05    144.659  0.036\n",
       "total_pop                       0.05     93.288  0.043\n",
       "pct_commute_drive_alone         0.03      0.006  0.232\n",
       "med_rooms_in_house              0.02      0.023  0.401\n",
       "pct_single_fam_detached        -0.02     -0.007  0.348\n",
       "pop_density_k_km               -0.07     -0.672  0.000\n",
       "pct_built_before_1940          -0.07     -0.017  0.002\n",
       "distance_to_center_km          -0.08     -0.601  0.000\n",
       "pct_renting                    -0.13     -0.030  0.000\n",
       "pct_black                      -0.26     -0.083  0.000\n",
       "pct_foreign_born               -0.28     -0.047  0.000\n",
       "pct_below_poverty              -0.38     -0.057  0.000\n",
       "pct_burden                     -0.40     -0.060  0.000\n",
       "pct_hispanic                   -0.40     -0.102  0.000\n",
       "pct_same_residence_year_ago    -0.40     -0.040  0.000\n",
       "mean_travel_time_work          -0.42     -3.351  0.000\n",
       "renter_household_size          -0.45     -0.330  0.000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variables' effect sizes between over and underrepresented tracts\n",
    "predictors_no_dummies = [p for p in predictors_all if 'dummy' not in p]\n",
    "results = test_variables(over, under, predictors_no_dummies)\n",
    "effect_sizes = pd.DataFrame(results).T.sort_values('cohen_d', ascending=False)\n",
    "effect_sizes.reindex(columns=['cohen_d', 'diff_mean', 'p_val'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Cohen suggested that d=0.2 be considered a 'small' effect size, 0.5 represents a 'medium' effect size and 0.8 a 'large' effect size. This means that if two groups' means don't differ by 0.2 standard deviations or more, the difference is trivial, even if it is statistically signficant.\"\n",
    "\n",
    "Perhaps we can interpret small-medium effect size as absolute value 0.3 <= x < 0.5?\n",
    "\n",
    "d is not affected by units/sizes. So income and income_k will have same d."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at some smaller subset of key variables of interest, per city\n",
    "predictors_key = ['pct_white', 'renter_household_size', 'pct_below_poverty', 'pct_20_34',\n",
    "                  'pct_bachelors_or_higher', 'med_income_k', 'median_gross_rent_k']\n",
    "\n",
    "def significance(p):\n",
    "    if p <= 0.01:\n",
    "        return '*'\n",
    "    elif p <= 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "city_results = {}\n",
    "for city, group in df.groupby('place_name'):\n",
    "    mask = group[overrepresent_var] > 1\n",
    "    group_over = group[mask]\n",
    "    group_under = group[~mask]\n",
    "    group_results = test_variables(group_over, group_under, predictors_key)\n",
    "    var_d = {k:'{:.2f}{}'.format(v['cohen_d'], significance(v['p_val'])) for k, v in group_results.items()}\n",
    "    city_results[city] = var_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_income_k</th>\n",
       "      <th>median_gross_rent_k</th>\n",
       "      <th>pct_20_34</th>\n",
       "      <th>pct_bachelors_or_higher</th>\n",
       "      <th>pct_below_poverty</th>\n",
       "      <th>pct_white</th>\n",
       "      <th>renter_household_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Atlanta</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.55*</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.58*</td>\n",
       "      <td>-0.37*</td>\n",
       "      <td>0.48*</td>\n",
       "      <td>-0.38*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austin</th>\n",
       "      <td>0.44*</td>\n",
       "      <td>0.45*</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.69*</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.69*</td>\n",
       "      <td>-0.38*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baltimore</th>\n",
       "      <td>0.80*</td>\n",
       "      <td>0.71*</td>\n",
       "      <td>1.07*</td>\n",
       "      <td>1.32*</td>\n",
       "      <td>-0.59*</td>\n",
       "      <td>1.15*</td>\n",
       "      <td>-0.71*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Birmingham</th>\n",
       "      <td>0.79*</td>\n",
       "      <td>0.89*</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.71*</td>\n",
       "      <td>-0.87*</td>\n",
       "      <td>0.50*</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston</th>\n",
       "      <td>0.41*</td>\n",
       "      <td>1.14*</td>\n",
       "      <td>1.26*</td>\n",
       "      <td>1.36*</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.98*</td>\n",
       "      <td>-1.24*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           med_income_k median_gross_rent_k pct_20_34 pct_bachelors_or_higher  \\\n",
       "Atlanta            0.37               0.55*      0.31                   0.58*   \n",
       "Austin            0.44*               0.45*     -0.01                   0.69*   \n",
       "Baltimore         0.80*               0.71*     1.07*                   1.32*   \n",
       "Birmingham        0.79*               0.89*      0.01                   0.71*   \n",
       "Boston            0.41*               1.14*     1.26*                   1.36*   \n",
       "\n",
       "           pct_below_poverty pct_white renter_household_size  \n",
       "Atlanta               -0.37*     0.48*                -0.38*  \n",
       "Austin                 -0.23     0.69*                -0.38*  \n",
       "Baltimore             -0.59*     1.15*                -0.71*  \n",
       "Birmingham            -0.87*     0.50*                 -0.10  \n",
       "Boston                  0.03     0.98*                -1.24*  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_effect_sizes = pd.DataFrame(city_results).T\n",
    "city_effect_sizes.index = city_effect_sizes.index.map(lambda x: x.split(', ')[0])\n",
    "city_effect_sizes.head()\n",
    "#city_effect_sizes.sort_values(by='mean_travel_time_work')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the predictors' relationships with each other\n",
    "\n",
    "and reduce multicollinearity among the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pop_density_k_km         renter_occupied_units_km    0.935369\n",
       "pct_foreign_born         pct_english_only            0.868093\n",
       "pct_renting              med_rooms_in_house          0.816963\n",
       "pct_hispanic             pct_english_only            0.811745\n",
       "pct_single_fam_detached  pct_renting                 0.753678\n",
       "med_income_k             pct_below_poverty           0.745893\n",
       "median_gross_rent_k      med_income_k                0.737837\n",
       "med_income_k             pct_bachelors_or_higher     0.734205\n",
       "med_rooms_in_house       pct_single_fam_detached     0.726489\n",
       "pct_commute_drive_alone  pop_density_k_km            0.722806\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these predictor vars have the highest pairwise correlations\n",
    "correlations = df[sorted(predictors_no_dummies)].corr()\n",
    "correlations.stack().abs().sort_values(ascending=False)[len(predictors_no_dummies):].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "cax = ax.matshow(correlations, cmap=plt.cm.PiYG_r)\n",
    "fig.colorbar(cax, fraction=0.045, pad=0.02)\n",
    "plt.xticks(range(len(correlations.columns)), correlations.columns, rotation=90)\n",
    "plt.yticks(range(len(correlations.columns)), correlations.columns)\n",
    "plt.savefig('images/correlation_matrix.jpg', bbox_inches='tight', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix of scatter plots for a subset of explanatory variables\n",
    "X = df[predictors_key]\n",
    "plots_array = scatter_matrix(X, figsize=(35, 35), alpha=0.2, s=2, diagonal='kde')\n",
    "plt.savefig('images/scatter_matrix.jpg', bbox_inches='tight', dpi=90)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce multicollinearity using predictors' variance inflation factors and design matrix's condition number\n",
    "\n",
    "A high condition number indicates multicollinearity. Rule of thumb, you want this to be below ~20 (in real-world applied analyses it will often be a bit higher though). Condition number is the ratio of the largest eigenvalue in the design matrix to the smallest. In other words, the large condition number in this case results from scaling rather than from multicollinearity. If we have just one variable with units in the thousands (ie, a large eigenvalue) and add a constant with units of 1 (ie, a small eigenvalue), we'll get a large condition number as the ratio, and statsmodels warns of multicollinearity. If you standardize the design matrix, you'll see condition number without the scaling effects.\n",
    "\n",
    "VIF is a measure for the collinearity of one variable with all the others. As a rule of thumb, a VIF > 10 indicates strong multicollinearity. If multicollinearity is present in our regression model, the correlated predictors can have large standard errors and thus become insignificant, even though they are theoretically important. By removing redundant predictors, we'll have more sensible regression results for the ones we left in. In statsmodels, the function expects the presence of a constant in the matrix of explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create design matrix 'X' and add constant\n",
    "X = df.dropna()[predictors_all]\n",
    "Xc = add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397573.1492424338\n",
      "252924.00079147593\n",
      "45.93047400774799\n"
     ]
    }
   ],
   "source": [
    "# calculate condition number with all predictors and constant (really high)\n",
    "print(np.linalg.cond(Xc))\n",
    "print(np.linalg.cond(X))\n",
    "print(np.linalg.cond(zscore(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                       2227.264620\n",
       "pct_black                    115.275469\n",
       "pct_white                    109.476258\n",
       "pct_hispanic                  82.923529\n",
       "pct_asian                     22.012179\n",
       "pct_english_only              18.306438\n",
       "pop_density_k_km              14.122618\n",
       "renter_occupied_units_km      13.832661\n",
       "pct_renting                    9.430405\n",
       "med_income_k                   8.790471\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate VIF for all predictors and constant (really high) then view top 10\n",
    "vifs = [vif(Xc.values, i) for i in range(len(Xc.columns))]\n",
    "pd.Series(data=vifs, index=Xc.columns).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ We have a high condition number and high VIFs, so we should remove redundant or unimportant predictors from model to reduce multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                          243.959781\n",
       "med_income_k                     4.091008\n",
       "median_gross_rent_k              3.169320\n",
       "med_rooms_in_house               3.149822\n",
       "pct_20_34                        2.925504\n",
       "pct_college_grad_student         2.587864\n",
       "renter_household_size            2.563896\n",
       "pct_white                        2.359638\n",
       "pct_same_residence_year_ago      2.037508\n",
       "pct_english_only                 2.000873\n",
       "mean_travel_time_work            1.983682\n",
       "distance_to_center_km            1.748052\n",
       "pct_built_before_1940            1.527182\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove some predictors\n",
    "remove = ['pop_density_k_km', 'renter_occupied_units_km','pct_burden', \n",
    "          'count_renter_occupied_units', 'total_pop', 'pct_foreign_born', \n",
    "          'pct_renting', 'pct_commute_drive_alone', 'med_home_value_k', \n",
    "          'pct_single_fam_detached', 'median_age', 'rental_vacancy_rate',\n",
    "          'pct_nonrelatives_household', 'pct_below_poverty', 'pct_bachelors_or_higher',\n",
    "          'dummy_asian', 'dummy_black', 'dummy_hispanic', 'dummy_white',\n",
    "          'pct_asian', 'pct_black', 'pct_hispanic']\n",
    "\n",
    "X = df.dropna()[predictors_all].drop(columns=remove)\n",
    "predictors_reduced = sorted(X.columns)\n",
    "Xc = add_constant(X)\n",
    "vifs = [vif(Xc.values, i) for i in range(len(Xc.columns))]\n",
    "pd.Series(data=vifs, index=Xc.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542.7101970950444\n",
      "1085.9735207823373\n",
      "5.106415780498562\n"
     ]
    }
   ],
   "source": [
    "# calculate condition number with reduced predictors\n",
    "print(np.linalg.cond(Xc))\n",
    "print(np.linalg.cond(X))\n",
    "print(np.linalg.cond(zscore(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to multicollinearity, we keep dummies for black and hispanic majority tracts, but leave out white dummy. pct_bachelors_or_higher is strongly multicollinear with White dummy and pct white and med_income, so we have to leave it out as it is redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "median_gross_rent_k          med_income_k                   0.738751\n",
       "pct_college_grad_student     pct_20_34                      0.692314\n",
       "pct_20_34                    pct_same_residence_year_ago    0.593674\n",
       "med_income_k                 pct_white                      0.572025\n",
       "med_rooms_in_house           pct_20_34                      0.532764\n",
       "renter_household_size        pct_college_grad_student       0.470721\n",
       "pct_college_grad_student     pct_same_residence_year_ago    0.466810\n",
       "renter_household_size        pct_white                      0.461049\n",
       "                             pct_english_only               0.435228\n",
       "pct_same_residence_year_ago  mean_travel_time_work          0.415480\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now these predictor vars have the highest pairwise correlations\n",
    "# compare to where we did this earlier: the top 10 are much less correlated now\n",
    "correlations = X.corr()\n",
    "correlations.stack().abs().sort_values(ascending=False)[len(X.columns):].drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the response variable's relationship with the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bivariate regression, show r^2 and p-value and plot\n",
    "def bivariate_regress(df, response, predictor, ax):\n",
    "\n",
    "    # first regress y on x to get slope, intercept, r, p-value, and std error\n",
    "    x = df[predictor]\n",
    "    y = df[response]\n",
    "    m, b, r, p, std_err = linregress(x=x, y=y)\n",
    "    y_line = m * x + b\n",
    "\n",
    "    # then scatterplot with bivariate line\n",
    "    ax.scatter(x, y, s=2, marker='.', zorder=1)\n",
    "    ax.plot(x, y_line, ls='--', c='k', alpha=0.5, linewidth=1, zorder=2)\n",
    "    ax.set_xlim((x.min(), x.max()))\n",
    "    ax.set_ylim((y.min(), y.max()))\n",
    "    ax.set_xlabel(predictor)\n",
    "    ax.set_ylabel(response)\n",
    "    ax.set_title('r2={:.3f}, m={:.3f}, p={:.3f}'.format(r**2, m, p))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axes\n",
    "n = len(predictors_reduced)\n",
    "ncols = int(np.ceil(np.sqrt(n)))\n",
    "nrows = int(np.ceil(n / ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n",
    "axes = [item for sublist in axes for item in sublist]\n",
    "\n",
    "# get pairs of dep_var vs ind_var\n",
    "response = 'bias_log'\n",
    "var_pairs = [(response, predictor) for predictor in predictors_reduced]\n",
    "\n",
    "# for each axis and pair of variables, plot a simple regression\n",
    "for ax, (response, predictor) in zip(axes, var_pairs):\n",
    "    ax = bivariate_regress(df.dropna(), response, predictor, ax)\n",
    "\n",
    "# save to disk and show\n",
    "fig.savefig('images/scatter_response_vs_predictors_original.jpg', bbox_inches='tight', dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform predictors for better linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['med_income_k'] = np.log(df['med_income_k'])\n",
    "df['distance_to_center_km'] = np.log(df['distance_to_center_km'])\n",
    "df['mean_travel_time_work'] = np.log(df['mean_travel_time_work'])\n",
    "df['renter_household_size'] = np.log(df['renter_household_size'])\n",
    "\n",
    "# add any interaction terms\n",
    "df['pct_white*income'] = df['pct_white'] * df['med_income_k']\n",
    "predictors_reduced = sorted(set(predictors_reduced + ['pct_white*income']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axes\n",
    "n = len(predictors_reduced)\n",
    "ncols = int(np.ceil(np.sqrt(n)))\n",
    "nrows = int(np.ceil(n / ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n",
    "axes = [item for sublist in axes for item in sublist]\n",
    "\n",
    "# get pairs of dep_var vs ind_var\n",
    "response = 'bias_log'\n",
    "var_pairs = [(response, predictor) for predictor in predictors_reduced]\n",
    "\n",
    "# for each axis and pair of variables, plot a simple regression\n",
    "for ax, (response, predictor) in zip(axes, var_pairs):\n",
    "    ax = bivariate_regress(df.dropna(), response, predictor, ax)\n",
    "\n",
    "# save to disk and show\n",
    "fig.savefig('images/scatter_response_vs_predictors_transformed.jpg', bbox_inches='tight', dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add city dummies to control for regional differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dummies\n",
    "place_names = sorted(df['place_name'].unique())\n",
    "for place_name in place_names:\n",
    "    df[place_name] = df['place_name'].map(lambda x: 1 if x==place_name else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove one dummy to prevent perfect collinearity\n",
    "# ie, a subset of predictors sums to 1 (which full set of dummies will do), and 1 ∝ the constant\n",
    "predictors = predictors_reduced + place_names[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate regression models to predict Craigslist over- or under-representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12328\n",
      "12224\n"
     ]
    }
   ],
   "source": [
    "X = df[predictors]\n",
    "print(len(X))\n",
    "X = X.dropna()\n",
    "y = df.loc[X.index]['bias_log']\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               bias_log   R-squared:                       0.296\n",
      "Model:                            OLS   Adj. R-squared:                  0.292\n",
      "Method:                 Least Squares   F-statistic:                     82.30\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):               0.00\n",
      "Time:                        23:42:13   Log-Likelihood:                -15804.\n",
      "No. Observations:               12224   AIC:                         3.173e+04\n",
      "Df Residuals:                   12161   BIC:                         3.220e+04\n",
      "Df Model:                          62                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                          -3.0077      0.262    -11.478      0.000      -3.521      -2.494\n",
      "distance_to_center_km          -0.1414      0.016     -8.627      0.000      -0.174      -0.109\n",
      "mean_travel_time_work          -0.1231      0.059     -2.097      0.036      -0.238      -0.008\n",
      "med_income_k                    0.4585      0.039     11.903      0.000       0.383       0.534\n",
      "med_rooms_in_house              0.0591      0.015      3.916      0.000       0.030       0.089\n",
      "median_gross_rent_k             0.6716      0.043     15.531      0.000       0.587       0.756\n",
      "pct_20_34                       0.6730      0.142      4.744      0.000       0.395       0.951\n",
      "pct_built_before_1940          -0.2323      0.047     -4.952      0.000      -0.324      -0.140\n",
      "pct_college_grad_student        0.3843      0.074      5.160      0.000       0.238       0.530\n",
      "pct_english_only                0.4156      0.052      7.926      0.000       0.313       0.518\n",
      "pct_same_residence_year_ago    -0.7311      0.121     -6.040      0.000      -0.968      -0.494\n",
      "pct_white                       0.5797      0.255      2.272      0.023       0.079       1.080\n",
      "pct_white*income               -0.1400      0.064     -2.187      0.029      -0.266      -0.015\n",
      "renter_household_size          -0.3528      0.050     -7.082      0.000      -0.450      -0.255\n",
      "Atlanta, GA                     0.5461      0.104      5.247      0.000       0.342       0.750\n",
      "Austin, TX                      0.6074      0.095      6.410      0.000       0.422       0.793\n",
      "Baltimore, MD                   0.6603      0.094      7.057      0.000       0.477       0.844\n",
      "Birmingham, AL                  1.0041      0.115      8.744      0.000       0.779       1.229\n",
      "Boston, MA                      0.0379      0.097      0.391      0.696      -0.152       0.228\n",
      "Buffalo, NY                     1.3355      0.127     10.511      0.000       1.086       1.585\n",
      "Charlotte, NC                   0.3303      0.096      3.427      0.001       0.141       0.519\n",
      "Chicago, IL                     0.4684      0.076      6.158      0.000       0.319       0.618\n",
      "Cincinnati, OH                  1.2224      0.110     11.076      0.000       1.006       1.439\n",
      "Cleveland, OH                   1.5586      0.101     15.423      0.000       1.361       1.757\n",
      "Columbus, OH                    0.7865      0.095      8.267      0.000       0.600       0.973\n",
      "Dallas, TX                      0.5360      0.086      6.232      0.000       0.367       0.705\n",
      "Denver, CO                      0.4009      0.103      3.903      0.000       0.200       0.602\n",
      "Detroit, MI                     1.6096      0.090     17.795      0.000       1.432       1.787\n",
      "Hartford, CT                    1.0833      0.159      6.798      0.000       0.771       1.396\n",
      "Houston, TX                     0.7360      0.081      9.125      0.000       0.578       0.894\n",
      "Indianapolis, IN                0.8056      0.097      8.272      0.000       0.615       0.997\n",
      "Jacksonville, FL                0.7930      0.102      7.786      0.000       0.593       0.993\n",
      "Kansas City, MO                 1.1287      0.102     11.066      0.000       0.929       1.329\n",
      "Las Vegas, NV                   0.9918      0.102      9.734      0.000       0.792       1.192\n",
      "Los Angeles, CA                 0.5685      0.078      7.289      0.000       0.416       0.721\n",
      "Louisville, KY                  1.0819      0.118      9.130      0.000       0.850       1.314\n",
      "Memphis, TN                     1.0584      0.100     10.598      0.000       0.863       1.254\n",
      "Miami, FL                       0.3822      0.114      3.358      0.001       0.159       0.605\n",
      "Milwaukee, WI                   1.1058      0.096     11.578      0.000       0.919       1.293\n",
      "Minneapolis, MN                 0.6531      0.109      5.975      0.000       0.439       0.867\n",
      "Nashville, TN                   0.7823      0.104      7.535      0.000       0.579       0.986\n",
      "New Orleans, LA                 1.0029      0.099     10.116      0.000       0.809       1.197\n",
      "New York, NY                    0.8686      0.075     11.629      0.000       0.722       1.015\n",
      "Oklahoma City, OK               1.0523      0.098     10.708      0.000       0.860       1.245\n",
      "Orlando, FL                     0.6042      0.120      5.035      0.000       0.369       0.839\n",
      "Philadelphia, PA                0.7528      0.084      9.011      0.000       0.589       0.917\n",
      "Phoenix, AZ                     0.8991      0.087     10.322      0.000       0.728       1.070\n",
      "Pittsburgh, PA                  0.9410      0.109      8.640      0.000       0.728       1.154\n",
      "Portland, OR                    0.4466      0.100      4.445      0.000       0.250       0.644\n",
      "Providence, RI                  0.9655      0.160      6.049      0.000       0.653       1.278\n",
      "Raleigh, NC                     0.5066      0.116      4.355      0.000       0.279       0.735\n",
      "Richmond, VA                    0.4770      0.131      3.638      0.000       0.220       0.734\n",
      "Riverside, CA                   0.5565      0.124      4.498      0.000       0.314       0.799\n",
      "Sacramento, CA                  0.5862      0.108      5.443      0.000       0.375       0.797\n",
      "Salt Lake City, UT              0.2936      0.139      2.112      0.035       0.021       0.566\n",
      "San Antonio, TX                 0.9033      0.089     10.174      0.000       0.729       1.077\n",
      "San Diego, CA                   0.2228      0.089      2.517      0.012       0.049       0.396\n",
      "San Francisco, CA               0.1418      0.095      1.493      0.136      -0.044       0.328\n",
      "San Jose, CA                    0.0332      0.094      0.355      0.723      -0.150       0.217\n",
      "Seattle, WA                     0.0874      0.103      0.850      0.395      -0.114       0.289\n",
      "St. Louis, MO                   0.9188      0.113      8.140      0.000       0.698       1.140\n",
      "Tampa, FL                       0.7725      0.110      7.053      0.000       0.558       0.987\n",
      "Virginia Beach, VA              0.3337      0.116      2.869      0.004       0.106       0.562\n",
      "==============================================================================\n",
      "Omnibus:                      772.268   Durbin-Watson:                   1.858\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1079.561\n",
      "Skew:                           0.559   Prob(JB):                    3.77e-235\n",
      "Kurtosis:                       3.934   Cond. No.                         519.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# estimate a model across the full data set (all cities)\n",
    "Xc = add_constant(X)\n",
    "model = sm.OLS(y, Xc)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ if we get warnings about multicollinearity, but have good VIF scores and significant variables, then check a standardized regression (below) to see if it's just scaling or the intercept/constant causing it (intercept shouldn't cause high condition number if we center/standardize our predictors). A high condition number indicates multicollinearity. Rule of thumb, you want this to be below ~20.\n",
    "\n",
    "durbin-watson tests for autocorrelation. a value around 1.5 to 2.5 is considered fine.\n",
    "\n",
    "omnibus tests for normality of residuals; if prob < 0.05, we reject the null hypothesis that they are normally distributed. skew and kurtosis describe their distribution.\n",
    "\n",
    "jarque-bera tests for normality of residuals; if prob < 0.05, we reject the null hypothesis that they are normally distributed\n",
    "\n",
    "Interaction term shows that the positive effect of income matters less as tract gets whiter and that the positive effect of white matters less as tract gets richer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               bias_log   R-squared:                       0.296\n",
      "Model:                            OLS   Adj. R-squared:                  0.292\n",
      "Method:                 Least Squares   F-statistic:                     82.30\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):               0.00\n",
      "Time:                        23:42:13   Log-Likelihood:                -15204.\n",
      "No. Observations:               12224   AIC:                         3.053e+04\n",
      "Df Residuals:                   12161   BIC:                         3.100e+04\n",
      "Df Model:                          62                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                       -1.457e-15      0.008  -1.91e-13      1.000      -0.015       0.015\n",
      "distance_to_center_km          -0.1067      0.012     -8.627      0.000      -0.131      -0.082\n",
      "mean_travel_time_work          -0.0318      0.015     -2.097      0.036      -0.061      -0.002\n",
      "med_income_k                    0.2351      0.020     11.903      0.000       0.196       0.274\n",
      "med_rooms_in_house              0.0637      0.016      3.916      0.000       0.032       0.096\n",
      "median_gross_rent_k             0.2373      0.015     15.531      0.000       0.207       0.267\n",
      "pct_20_34                       0.0648      0.014      4.744      0.000       0.038       0.092\n",
      "pct_built_before_1940          -0.0578      0.012     -4.952      0.000      -0.081      -0.035\n",
      "pct_college_grad_student        0.0692      0.013      5.160      0.000       0.043       0.095\n",
      "pct_english_only                0.1010      0.013      7.926      0.000       0.076       0.126\n",
      "pct_same_residence_year_ago    -0.0709      0.012     -6.040      0.000      -0.094      -0.048\n",
      "pct_white                       0.1662      0.073      2.272      0.023       0.023       0.310\n",
      "pct_white*income               -0.1752      0.080     -2.187      0.029      -0.332      -0.018\n",
      "renter_household_size          -0.0945      0.013     -7.082      0.000      -0.121      -0.068\n",
      "Atlanta, GA                     0.0539      0.010      5.247      0.000       0.034       0.074\n",
      "Austin, TX                      0.0760      0.012      6.410      0.000       0.053       0.099\n",
      "Baltimore, MD                   0.0792      0.011      7.057      0.000       0.057       0.101\n",
      "Birmingham, AL                  0.0882      0.010      8.744      0.000       0.068       0.108\n",
      "Boston, MA                      0.0042      0.011      0.391      0.696      -0.017       0.025\n",
      "Buffalo, NY                     0.1012      0.010     10.511      0.000       0.082       0.120\n",
      "Charlotte, NC                   0.0399      0.012      3.427      0.001       0.017       0.063\n",
      "Chicago, IL                     0.1100      0.018      6.158      0.000       0.075       0.145\n",
      "Cincinnati, OH                  0.1152      0.010     11.076      0.000       0.095       0.136\n",
      "Cleveland, OH                   0.1763      0.011     15.423      0.000       0.154       0.199\n",
      "Columbus, OH                    0.1056      0.013      8.267      0.000       0.081       0.131\n",
      "Dallas, TX                      0.0859      0.014      6.232      0.000       0.059       0.113\n",
      "Denver, CO                      0.0410      0.011      3.903      0.000       0.020       0.062\n",
      "Detroit, MI                     0.2328      0.013     17.795      0.000       0.207       0.258\n",
      "Hartford, CT                    0.0582      0.009      6.798      0.000       0.041       0.075\n",
      "Houston, TX                     0.1579      0.017      9.125      0.000       0.124       0.192\n",
      "Indianapolis, IN                0.1001      0.012      8.272      0.000       0.076       0.124\n",
      "Jacksonville, FL                0.0869      0.011      7.786      0.000       0.065       0.109\n",
      "Kansas City, MO                 0.1251      0.011     11.066      0.000       0.103       0.147\n",
      "Las Vegas, NV                   0.1070      0.011      9.734      0.000       0.085       0.129\n",
      "Los Angeles, CA                 0.1473      0.020      7.289      0.000       0.108       0.187\n",
      "Louisville, KY                  0.0914      0.010      9.130      0.000       0.072       0.111\n",
      "Memphis, TN                     0.1234      0.012     10.598      0.000       0.101       0.146\n",
      "Miami, FL                       0.0334      0.010      3.358      0.001       0.014       0.053\n",
      "Milwaukee, WI                   0.1368      0.012     11.578      0.000       0.114       0.160\n",
      "Minneapolis, MN                 0.0603      0.010      5.975      0.000       0.041       0.080\n",
      "Nashville, TN                   0.0825      0.011      7.535      0.000       0.061       0.104\n",
      "New Orleans, LA                 0.1112      0.011     10.116      0.000       0.090       0.133\n",
      "New York, NY                    0.3118      0.027     11.629      0.000       0.259       0.364\n",
      "Oklahoma City, OK               0.1329      0.012     10.708      0.000       0.109       0.157\n",
      "Orlando, FL                     0.0481      0.010      5.035      0.000       0.029       0.067\n",
      "Philadelphia, PA                0.1231      0.014      9.011      0.000       0.096       0.150\n",
      "Phoenix, AZ                     0.1482      0.014     10.322      0.000       0.120       0.176\n",
      "Pittsburgh, PA                  0.0898      0.010      8.640      0.000       0.069       0.110\n",
      "Portland, OR                    0.0483      0.011      4.445      0.000       0.027       0.070\n",
      "Providence, RI                  0.0518      0.009      6.049      0.000       0.035       0.069\n",
      "Raleigh, NC                     0.0432      0.010      4.355      0.000       0.024       0.063\n",
      "Richmond, VA                    0.0333      0.009      3.638      0.000       0.015       0.051\n",
      "Riverside, CA                   0.0416      0.009      4.498      0.000       0.023       0.060\n",
      "Sacramento, CA                  0.0552      0.010      5.443      0.000       0.035       0.075\n",
      "Salt Lake City, UT              0.0192      0.009      2.112      0.035       0.001       0.037\n",
      "San Antonio, TX                 0.1398      0.014     10.174      0.000       0.113       0.167\n",
      "San Diego, CA                   0.0331      0.013      2.517      0.012       0.007       0.059\n",
      "San Francisco, CA               0.0168      0.011      1.493      0.136      -0.005       0.039\n",
      "San Jose, CA                    0.0043      0.012      0.355      0.723      -0.019       0.028\n",
      "Seattle, WA                     0.0087      0.010      0.850      0.395      -0.011       0.029\n",
      "St. Louis, MO                   0.0811      0.010      8.140      0.000       0.062       0.101\n",
      "Tampa, FL                       0.0716      0.010      7.053      0.000       0.052       0.092\n",
      "Virginia Beach, VA              0.0283      0.010      2.869      0.004       0.009       0.048\n",
      "==============================================================================\n",
      "Omnibus:                      772.268   Durbin-Watson:                   1.858\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1079.561\n",
      "Skew:                           0.559   Prob(JB):                    3.77e-235\n",
      "Kurtosis:                       3.934   Cond. No.                         28.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# estimate a standardized model across the full data set (all cities)\n",
    "y_stdrd = pd.Series(data=zscore(y), index=y.index, name=y.name)\n",
    "X_stdrd = pd.DataFrame(data=zscore(X), index=X.index, columns=X.columns)\n",
    "Xc_stdrd = add_constant(X_stdrd)\n",
    "model_stdrd = sm.OLS(y_stdrd, Xc_stdrd)\n",
    "result_stdrd = model_stdrd.fit()\n",
    "print(result_stdrd.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.58249374415225"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# condition number to test for multicollinearity\n",
    "# rule of thumb, you want this below 20\n",
    "np.linalg.cond(model_stdrd.exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot observed (y-axis) vs fitted (x-axis)\n",
    "observed = model.endog #actual response var\n",
    "fitted = result.fittedvalues #predicted response var\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(x=fitted, y=observed, s=0.2)\n",
    "ax.set_xlabel('fitted')\n",
    "ax.set_ylabel('observed')\n",
    "ax.set_title('actual vs predicted')\n",
    "\n",
    "# draw a 45° y=x line\n",
    "ax.set_xlim((min(np.append(observed, fitted)), max(np.append(observed, fitted))))\n",
    "ax.set_ylim((min(np.append(observed, fitted)), max(np.append(observed, fitted))))\n",
    "ax.plot(ax.get_xlim(), ax.get_ylim(), ls='--', c='k', alpha=0.5)\n",
    "\n",
    "fig.savefig('images/diagnostic_actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized residuals: the internally studentized residuals\n",
    "resids_stud = result.get_influence().resid_studentized_internal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals plot for heteroskedasticity\n",
    "# want this to look like a random point pattern with no discernable trend\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(x=result.fittedvalues, y=resids_stud, s=0.2)\n",
    "ax.axhline(y=0, ls='--', c='k', alpha=0.5)\n",
    "ax.set_title('residuals vs fitted plot')\n",
    "ax.set_xlabel('fitted values')\n",
    "ax.set_ylabel('standardized residuals')\n",
    "\n",
    "fig.savefig('images/diagnostic_residuals_vs_fitted.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale-location plot (aka spread-location plot)\n",
    "# want this to look like a random point pattern with no discernable trend\n",
    "resids_stud_abs_sqrt = np.sqrt(np.abs(resids_stud))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(x=result.fittedvalues, y=resids_stud_abs_sqrt, s=0.2)\n",
    "ax.set_title('scale-location plot')\n",
    "ax.set_xlabel('fitted values')\n",
    "ax.set_ylabel('square-root absolute standardized residuals ')\n",
    "\n",
    "fig.savefig('images/diagnostic_scale_location.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1078.97, 0.0, 0.558, 3.934]\n"
     ]
    }
   ],
   "source": [
    "# are residuals approximately normally distributed?\n",
    "# null hypothesis is normal dist, p-value < 0.05 means reject null\n",
    "# typically want skew and kurtosis to be within -2 to 2\n",
    "# but with sufficiently large sample size, we'll always reject the null\n",
    "jb, jb_p, skew, kurtosis = sms.jarque_bera(resids_stud)\n",
    "print([round(x, 3) for x in [jb, jb_p, skew, kurtosis]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are residuals approximately normally distributed?\n",
    "# visuals can be more useful than test-statistics\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax = pd.Series(resids_stud).hist(bins=30, ax=ax)\n",
    "ax.set_title('standardized residuals histogram')\n",
    "fig.savefig('images/diagnostic_residuals_histogram.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are residuals approximately normally distributed?\n",
    "# you want the points to tightly follow the line\n",
    "# the hist above and qq plot below are ok, not terrible\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "fig = sm.qqplot(resids_stud, line='45', ax=ax)\n",
    "ax.set_title('normal probability plot of the standardized residuals')\n",
    "fig.savefig('images/diagnostic_residuals_qq_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure and axes\n",
    "n = len(predictors_reduced)\n",
    "ncols = int(np.ceil(np.sqrt(n)))\n",
    "nrows = int(np.ceil(n / ncols))\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(ncols*5, nrows*5))\n",
    "axes = [item for sublist in axes for item in sublist]\n",
    "\n",
    "resids_stud = result.get_influence().resid_studentized_internal\n",
    "\n",
    "# for each axis and variable, scatterplot the resids\n",
    "for ax, var in zip(axes, sorted(predictors_reduced)):\n",
    "    ax.scatter(x=X[var], y=resids_stud, s=0.2)\n",
    "    ax.set_xlabel(var)\n",
    "    ax.set_ylabel('standardized residuals')\n",
    "\n",
    "# save to disk and show\n",
    "fig.savefig('images/scatter_resids_vs_predictors.jpg', bbox_inches='tight', dpi=150)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier detection\n",
    "#ot = result.outlier_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\not['student_resid_abs'] = ot['student_resid'].abs()\\nthreshold = ot['student_resid_abs'].quantile(0.99)\\nbad = ot[ot['student_resid_abs'] >= threshold]\\ndf2 = df.drop(labels=bad.index)\\nlen(df2)\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ot['student_resid_abs'] = ot['student_resid'].abs()\n",
    "threshold = ot['student_resid_abs'].quantile(0.99)\n",
    "bad = ot[ot['student_resid_abs'] >= threshold]\n",
    "df2 = df.drop(labels=bad.index)\n",
    "len(df2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression model for just one city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449 1663\n"
     ]
    }
   ],
   "source": [
    "# subset data for a single city\n",
    "place_name = 'New York, NY'\n",
    "df_city = df[df['place_name']==place_name]\n",
    "print(sum(df_city['bias_ratio']>1), sum(df_city['bias_ratio']<=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2112\n",
      "2097\n"
     ]
    }
   ],
   "source": [
    "X_city = df_city[predictors_reduced]\n",
    "print(len(X_city))\n",
    "X_city = X_city.dropna()\n",
    "y_city = df_city.loc[X_city.index]['bias_log']\n",
    "print(len(X_city))\n",
    "Xc_city = add_constant(X_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               bias_log   R-squared:                       0.384\n",
      "Model:                            OLS   Adj. R-squared:                  0.380\n",
      "Method:                 Least Squares   F-statistic:                     99.77\n",
      "Date:                Fri, 09 Mar 2018   Prob (F-statistic):          8.10e-208\n",
      "Time:                        23:42:18   Log-Likelihood:                -2161.9\n",
      "No. Observations:                2097   AIC:                             4352.\n",
      "Df Residuals:                    2083   BIC:                             4431.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                          -2.5325      0.531     -4.768      0.000      -3.574      -1.491\n",
      "distance_to_center_km          -0.4318      0.043    -10.032      0.000      -0.516      -0.347\n",
      "mean_travel_time_work           0.0243      0.127      0.191      0.849      -0.225       0.274\n",
      "med_income_k                    0.4870      0.073      6.662      0.000       0.344       0.630\n",
      "med_rooms_in_house              0.2202      0.027      8.009      0.000       0.166       0.274\n",
      "median_gross_rent_k             0.2156      0.079      2.713      0.007       0.060       0.371\n",
      "pct_20_34                       2.2326      0.283      7.903      0.000       1.679       2.787\n",
      "pct_built_before_1940           0.2968      0.069      4.310      0.000       0.162       0.432\n",
      "pct_college_grad_student       -0.2905      0.151     -1.918      0.055      -0.588       0.007\n",
      "pct_english_only                0.4286      0.085      5.013      0.000       0.261       0.596\n",
      "pct_same_residence_year_ago    -0.5806      0.304     -1.912      0.056      -1.176       0.015\n",
      "pct_white                       1.6365      0.465      3.519      0.000       0.724       2.549\n",
      "pct_white*income               -0.4291      0.116     -3.705      0.000      -0.656      -0.202\n",
      "renter_household_size          -0.4972      0.108     -4.587      0.000      -0.710      -0.285\n",
      "==============================================================================\n",
      "Omnibus:                      232.300   Durbin-Watson:                   1.870\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              434.322\n",
      "Skew:                           0.721   Prob(JB):                     4.88e-95\n",
      "Kurtosis:                       4.701   Cond. No.                         299.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# estimate a model for this single city\n",
    "model_city = sm.OLS(y_city, Xc_city)\n",
    "result_city = model_city.fit()\n",
    "print(result_city.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                          1276.889139\n",
       "pct_white*income                108.144950\n",
       "pct_white                        91.543432\n",
       "med_income_k                      5.728529\n",
       "median_gross_rent_k               3.379563\n",
       "distance_to_center_km             3.259965\n",
       "renter_household_size             3.042439\n",
       "med_rooms_in_house                2.820585\n",
       "mean_travel_time_work             2.686591\n",
       "pct_20_34                         2.279244\n",
       "pct_college_grad_student          2.148374\n",
       "pct_same_residence_year_ago       1.815523\n",
       "pct_english_only                  1.687600\n",
       "pct_built_before_1940             1.092935\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate variance inflation factor just for this city\n",
    "vifs_city = [vif(Xc_city.values, i) for i in range(len(Xc_city.columns))]\n",
    "pd.Series(data=vifs_city, index=Xc_city.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12328\n",
      "12224\n"
     ]
    }
   ],
   "source": [
    "X_logit = df[predictors_reduced]\n",
    "print(len(X_logit))\n",
    "X_logit = X_logit.dropna()\n",
    "y_logit = df.loc[X_logit.index]['is_over']\n",
    "print(len(X_logit))\n",
    "Xc_logit = add_constant(X_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.491901\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                is_over   No. Observations:                12224\n",
      "Model:                          Logit   Df Residuals:                    12210\n",
      "Method:                           MLE   Df Model:                           13\n",
      "Date:                Fri, 09 Mar 2018   Pseudo R-squ.:                  0.1234\n",
      "Time:                        23:42:18   Log-Likelihood:                -6013.0\n",
      "converged:                       True   LL-Null:                       -6859.7\n",
      "                                        LLR p-value:                     0.000\n",
      "===============================================================================================\n",
      "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "const                          -0.1203      0.549     -0.219      0.827      -1.196       0.955\n",
      "distance_to_center_km          -0.1153      0.039     -2.959      0.003      -0.192      -0.039\n",
      "mean_travel_time_work          -0.8863      0.123     -7.233      0.000      -1.126      -0.646\n",
      "med_income_k                    0.4912      0.109      4.507      0.000       0.278       0.705\n",
      "med_rooms_in_house              0.0212      0.036      0.595      0.552      -0.049       0.091\n",
      "median_gross_rent_k             1.0137      0.101     10.075      0.000       0.817       1.211\n",
      "pct_20_34                       1.2445      0.358      3.474      0.001       0.542       1.947\n",
      "pct_built_before_1940          -0.3097      0.107     -2.889      0.004      -0.520      -0.100\n",
      "pct_college_grad_student        0.2557      0.191      1.340      0.180      -0.118       0.630\n",
      "pct_english_only                1.0267      0.141      7.291      0.000       0.751       1.303\n",
      "pct_same_residence_year_ago    -1.6149      0.315     -5.131      0.000      -2.232      -0.998\n",
      "pct_white                      -0.4084      0.699     -0.584      0.559      -1.779       0.962\n",
      "pct_white*income                0.0731      0.177      0.414      0.679      -0.273       0.419\n",
      "renter_household_size          -0.7485      0.133     -5.618      0.000      -1.010      -0.487\n",
      "===============================================================================================\n",
      "Wall time: 44 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict whether or not tract is overrepresented on craigslist (yes/no)\n",
    "model_logit = sm.Logit(y_logit, Xc_logit)\n",
    "result_logit = model_logit.fit()\n",
    "print(result_logit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction\n",
    "\n",
    "### PCA with all the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[predictors_reduced].dropna()\n",
    "X = pd.DataFrame(scale(X.values), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n dimensions\n",
    "n = 5\n",
    "pca = PCA(n_components=n)\n",
    "pca.fit(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28991701, 0.23720171, 0.13056765, 0.09509767, 0.06001126])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# amount of variance that each component explains\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29 , 0.527, 0.658, 0.753, 0.813])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cumulative variance explained\n",
    "np.cumsum(np.round(pca.explained_variance_ratio_, decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pct_white</th>\n",
       "      <td>0.410</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_white*income</th>\n",
       "      <td>0.400</td>\n",
       "      <td>-0.309</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_college_grad_student</th>\n",
       "      <td>0.372</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.084</td>\n",
       "      <td>-0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_20_34</th>\n",
       "      <td>0.286</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_income_k</th>\n",
       "      <td>0.231</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_english_only</th>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>-0.276</td>\n",
       "      <td>-0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_gross_rent_k</th>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.295</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_built_before_1940</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.211</td>\n",
       "      <td>-0.722</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_rooms_in_house</th>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.427</td>\n",
       "      <td>-0.308</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>0.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_to_center_km</th>\n",
       "      <td>-0.194</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.289</td>\n",
       "      <td>-0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_same_residence_year_ago</th>\n",
       "      <td>-0.270</td>\n",
       "      <td>-0.296</td>\n",
       "      <td>0.114</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>-0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_travel_time_work</th>\n",
       "      <td>-0.271</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.442</td>\n",
       "      <td>-0.268</td>\n",
       "      <td>-0.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renter_household_size</th>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PC1    PC2    PC3    PC4    PC5\n",
       "pct_white                    0.410 -0.262 -0.037 -0.056 -0.095\n",
       "pct_white*income             0.400 -0.309 -0.004 -0.066 -0.061\n",
       "pct_college_grad_student     0.372  0.195  0.228  0.084 -0.067\n",
       "pct_20_34                    0.286  0.326  0.235  0.187  0.114\n",
       "med_income_k                 0.231 -0.415  0.275  0.042  0.117\n",
       "pct_english_only             0.230 -0.085 -0.464 -0.276 -0.089\n",
       "median_gross_rent_k          0.152 -0.295  0.494  0.092  0.244\n",
       "pct_built_before_1940        0.030  0.164  0.211 -0.722  0.290\n",
       "med_rooms_in_house          -0.057 -0.427 -0.308 -0.085  0.351\n",
       "distance_to_center_km       -0.194 -0.340  0.044  0.289 -0.438\n",
       "pct_same_residence_year_ago -0.270 -0.296  0.114 -0.348 -0.132\n",
       "mean_travel_time_work       -0.271 -0.045  0.442 -0.268 -0.399\n",
       "renter_household_size       -0.367 -0.106  0.088  0.243  0.559"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['PC{}'.format(i+1) for i in range(n)]\n",
    "pd.DataFrame(pca.components_, columns=X.columns, index=labels).T.sort_values('PC1', ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factor analysis with all the predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\decomposition\\factor_analysis.py:228: ConvergenceWarning: FactorAnalysis did not converge. You might want to increase the number of iterations.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=5,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n factors\n",
    "n = 5\n",
    "fa = FactorAnalysis(n_components=n)\n",
    "fa.fit(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fac1</th>\n",
       "      <th>Fac2</th>\n",
       "      <th>Fac3</th>\n",
       "      <th>Fac4</th>\n",
       "      <th>Fac5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pct_white*income</th>\n",
       "      <td>0.998</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_white</th>\n",
       "      <td>0.987</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_income_k</th>\n",
       "      <td>0.672</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>-0.497</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_gross_rent_k</th>\n",
       "      <td>0.402</td>\n",
       "      <td>-0.302</td>\n",
       "      <td>-0.334</td>\n",
       "      <td>0.581</td>\n",
       "      <td>-0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_english_only</th>\n",
       "      <td>0.367</td>\n",
       "      <td>0.260</td>\n",
       "      <td>-0.132</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_college_grad_student</th>\n",
       "      <td>0.326</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med_rooms_in_house</th>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>-0.459</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_20_34</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_to_center_km</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.419</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_built_before_1940</th>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.072</td>\n",
       "      <td>-0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_same_residence_year_ago</th>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>-0.469</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_travel_time_work</th>\n",
       "      <td>-0.346</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>0.208</td>\n",
       "      <td>-0.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>renter_household_size</th>\n",
       "      <td>-0.505</td>\n",
       "      <td>-0.856</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Fac1   Fac2   Fac3   Fac4   Fac5\n",
       "pct_white*income             0.998 -0.056 -0.002  0.001 -0.003\n",
       "pct_white                    0.987 -0.014  0.113 -0.043 -0.002\n",
       "med_income_k                 0.672 -0.275 -0.497  0.391  0.053\n",
       "median_gross_rent_k          0.402 -0.302 -0.334  0.581 -0.025\n",
       "pct_english_only             0.367  0.260 -0.132 -0.412  0.425\n",
       "pct_college_grad_student     0.326  0.434  0.265  0.465  0.321\n",
       "med_rooms_in_house           0.235 -0.521 -0.481 -0.459  0.328\n",
       "pct_20_34                    0.115  0.336  0.515  0.531  0.343\n",
       "distance_to_center_km       -0.010 -0.419 -0.313 -0.104 -0.152\n",
       "pct_built_before_1940       -0.039  0.176  0.084  0.072 -0.050\n",
       "pct_same_residence_year_ago -0.109 -0.335 -0.469 -0.179 -0.402\n",
       "mean_travel_time_work       -0.346 -0.119 -0.257  0.208 -0.397\n",
       "renter_household_size       -0.505 -0.856  0.063  0.013  0.003"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['Fac{}'.format(i+1) for i in range(n)]\n",
    "pd.DataFrame(fa.components_, columns=X.columns, index=labels).T.sort_values('Fac1', ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
